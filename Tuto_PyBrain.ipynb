{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PyBrain"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tutorial from PyBrain documentation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Quickstart"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Building a Network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.tools.shortcuts import buildNetwork\n",
      "net = buildNetwork(2, 3, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This call returns a network that has two inputs, three hidden and a single output neuron. In PyBrain, these layers are Module objects and they are already connected with FullConnection objects."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Activating a Network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The net is already initialized with random values - we can already calculate its output:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.activate([2, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "array([ 0.46746564])"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this we use the .activate() method, which expects a list, tuple or an array as input."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Examining the structure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How can we examine the structure of our network somewhat closer? In PyBrain, every part of a network has a name by which you can access it. When building networks with the buildNetwork shortcut, the parts are named automatically:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net['in']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<LinearLayer 'in'>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " net['hidden0']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<SigmoidLayer 'hidden0'>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net['out']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<LinearLayer 'out'>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The hidden layers have numbers at the end in order to distinguish between those."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "More sophisticated Networks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, we want more flexibility when building up networks. For instance, the hidden layer is constructed with the sigmoid squashing function per default: but in a lot of cases, this is not what we want. We can also supply different types of layers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.structure import TanhLayer\n",
      "net = buildNetwork(2, 3, 1, hiddenclass=TanhLayer)\n",
      "net['hidden0']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<TanhLayer 'hidden0'>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is more we can do. For example, we can also set a different class for the output layer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.structure import SoftmaxLayer\n",
      "net = buildNetwork(2, 3, 2, hiddenclass=TanhLayer, outclass=SoftmaxLayer)\n",
      "net.activate((2, 3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "array([ 0.04823478,  0.95176522])"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also tell the network to use a bias:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = buildNetwork(2, 3, 1, bias=True)\n",
      "net['bias']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<BiasUnit 'bias'>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This approach has of course some restrictions: for example, we can only construct a feedforward topology. But it is possible to create very sophisticated architectures with PyBrain, and it is also one of the library\u2019s strength to do so."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Building a DataSet"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order for our networks to learn anything, we need a dataset that contains inputs and targets. PyBrain has the pybrain.dataset package for this, and we will use the SupervisedDataSet class for our needs."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A customized DataSet"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The SupervisedDataSet class is used for standard supervised learning. It supports input and target values, whose size we have to specify on object creation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.datasets import SupervisedDataSet\n",
      "ds = SupervisedDataSet(2, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we have generated a dataset that supports two dimensional inputs and one dimensional targets."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Adding samples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A classic example for neural network training is the XOR function, so let\u2019s just build a dataset for this. We can do this by just adding samples to the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds.addSample((0, 0), (0,))\n",
      "ds.addSample((0, 1), (1,))\n",
      "ds.addSample((1, 0), (1,))\n",
      "ds.addSample((1, 1), (0,))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Examining the dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have a dataset that has 4 samples in it. We can check that with python\u2019s idiomatic way of checking the size of something:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(ds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also iterate over it in the standard way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for inpt, target in ds:\n",
      "    print inpt, target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  0.] [ 0.]\n",
        "[ 0.  1.] [ 1.]\n",
        "[ 1.  0.] [ 1.]\n",
        "[ 1.  1.] [ 0.]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can access the input and target field directly as arrays:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds['input']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([[ 0.,  0.],\n",
        "       [ 0.,  1.],\n",
        "       [ 1.,  0.],\n",
        "       [ 1.,  1.]])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds['target']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "array([[ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.]])"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also possible to clear a dataset again, and delete all the values from it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds.clear()\n",
      "ds['input']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([], shape=(0, 2), dtype=float64)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds['target']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "array([], shape=(0, 1), dtype=float64)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training your Network on your Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For adjusting parameters of modules in supervised learning, PyBrain has the concept of trainers. Trainers take a module and a dataset in order to train the module to fit the data in the dataset.\n",
      "\n",
      "A classic example for training is backpropagation. PyBrain comes with backpropagation, of course, and we will use the BackpropTrainer here:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.supervised.trainers import BackpropTrainer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have already build a dataset for XOR and we have also learned to build networks that can handle such problems. Let\u2019s just connect the two with a trainer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds.addSample((0, 0), (0,))\n",
      "ds.addSample((0, 1), (1,))\n",
      "ds.addSample((1, 0), (1,))\n",
      "ds.addSample((1, 1), (0,))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = buildNetwork(2, 3, 1, bias=True, hiddenclass=TanhLayer)\n",
      "trainer = BackpropTrainer(net, ds)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The trainer now knows about the network and the dataset and we can train the net on the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer.train()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "0.65282747005523212"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This call trains the net for one full epoch and returns a double proportional to the error. If we want to train the network until convergence, there is another method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer.trainUntilConvergence()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "([0.2712186984129315,\n",
        "  0.23990097827614279,\n",
        "  0.217537282123174,\n",
        "  0.2019910959582365,\n",
        "  0.19073214333336597,\n",
        "  0.1830308041063391,\n",
        "  0.17757278688023059,\n",
        "  0.17358443310919458,\n",
        "  0.17040915646824514,\n",
        "  0.16798325615836204,\n",
        "  0.16619535794935994,\n",
        "  0.16475151441854641,\n",
        "  0.16301291179553318,\n",
        "  0.16189381697549907,\n",
        "  0.16090398201218895,\n",
        "  0.15976732580193484,\n",
        "  0.15925303762300178,\n",
        "  0.15825349142042866,\n",
        "  0.15781115560265599,\n",
        "  0.15703746774885988,\n",
        "  0.15644775706158295,\n",
        "  0.15583038469366298,\n",
        "  0.15521721749806147,\n",
        "  0.15462007823949678,\n",
        "  0.15407451940440517,\n",
        "  0.15355414051632346,\n",
        "  0.15300890939327846,\n",
        "  0.15252425906041889,\n",
        "  0.15728335231675492],\n",
        " [0.19925256467565658,\n",
        "  0.16682081294266993,\n",
        "  0.14511546621259006,\n",
        "  0.12813315357097543,\n",
        "  0.11806486261123161,\n",
        "  0.10979793578034769,\n",
        "  0.10497818779289628,\n",
        "  0.10183026857897619,\n",
        "  0.099583269286135478,\n",
        "  0.098282780832052719,\n",
        "  0.097523845513645013,\n",
        "  0.097181628177953505,\n",
        "  0.096958237543134332,\n",
        "  0.096717986900906688,\n",
        "  0.096821024750647328,\n",
        "  0.097137202333617501,\n",
        "  0.097601652250018184,\n",
        "  0.09796594706836495,\n",
        "  0.098453411020722664,\n",
        "  0.098784565787318937,\n",
        "  0.099200227908598448,\n",
        "  0.09963053566205643,\n",
        "  0.10005310220232086,\n",
        "  0.10049554022097293,\n",
        "  0.10095309201072887,\n",
        "  0.10138147379175785,\n",
        "  0.10181287942515577,\n",
        "  0.10222859189209788,\n",
        "  0.10264420774931873])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This returns a whole bunch of data, which is nothing but a tuple containing the errors for every training epoch."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tutorials"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PyBrain\u2019s concept is to encapsulate different data processing algorithms in what we call a Module. A minimal Module contains a forward implementation depending on a collection of free parameters that can be adjusted, usually through some machine learning algorithm.\n",
      "\n",
      "Modules have an input and an output buffer, plus corresponding error buffers which are used in error backpropagation algorithms.\n",
      "\n",
      "They are assembled into objects of the class Network and are connected via Connection objects. These may contain a number of adjustable parameters themselves, such as weights.\n",
      "\n",
      "Note that a Network itself is again a Module, such that it is easy to build hierarchical networks as well. Shortcuts exist for building the most common network architectures, but in principle this system allows almost arbitrary connectionist systems to be assembled, as long as they form a directed acyclic graph.\n",
      "\n",
      "The free parameters of the Network are adjusted by means of a Trainer, which uses a Dataset to learn the optimum parameters from examples. For reinforcement learning experiments, a simulation environment with an associated optimization task is used instead of a Dataset."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![alt text](http://pybrain.org/docs/_images/dataprocessing_flowchart.jpg)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Building Networks with Modules and Connections"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This chapter will guide you to use PyBrain\u2019s most basic structural elements: the FeedForwardNetwork and RecurrentNetwork classes and with them the Module class and the Connection class. We have already seen how to create networks with the buildNetwork shortcut - but since this technique is limited in some ways, we will now explore how to create networks from the ground up."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Feed Forward Networks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will start with a simple example, building a multi layer perceptron.\n",
      "\n",
      "First we make a new FeedForwardNetwork object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.structure import FeedForwardNetwork\n",
      "n = FeedForwardNetwork()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we\u2019re constructing the input, hidden and output layers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.structure import LinearLayer, SigmoidLayer\n",
      "inLayer = LinearLayer(2)\n",
      "hiddenLayer = SigmoidLayer(3)\n",
      "outLayer = LinearLayer(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a couple of different classes of layers. For a complete list check out the modules package.\n",
      "\n",
      "In order to use them, we have to add them to the network:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.addInputModule(inLayer)\n",
      "n.addModule(hiddenLayer)\n",
      "n.addOutputModule(outLayer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can actually add multiple input and output modules. The net has to know which of its modules are input and output modules, in order to forward propagate input and to back propagate errors.\n",
      "\n",
      "It still needs to be explicitly determined how they should be connected. For this we use the most common connection type, which produces a full connectivity between layers, by connecting each neuron of one layer with each neuron of the other. This is implemented by the FullConnection "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.structure import FullConnection\n",
      "in_to_hidden = FullConnection(inLayer, hiddenLayer)\n",
      "hidden_to_out = FullConnection(hiddenLayer, outLayer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As with modules, we have to explicitly add them to the network:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.addConnection(in_to_hidden)\n",
      "n.addConnection(hidden_to_out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All the elements are in place now, so we can do the final step that makes our MLP usable, which is to call the .sortModules() method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.sortModules()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This call does some internal initialization which is necessary before the net can finally be used: for example, the modules are sorted topologically."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Examining a Network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can actually print networks and examine their structure:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FeedForwardNetwork-81\n",
        "   Modules:\n",
        "    [<LinearLayer 'LinearLayer-78'>, <SigmoidLayer 'SigmoidLayer-82'>, <LinearLayer 'LinearLayer-83'>]\n",
        "   Connections:\n",
        "    [<FullConnection 'FullConnection-79': 'SigmoidLayer-82' -> 'LinearLayer-83'>, <FullConnection 'FullConnection-80': 'LinearLayer-78' -> 'SigmoidLayer-82'>]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the output on your machine will not necessarily be the same.\n",
      "\n",
      "One way of using the network is to call its \u2018activate()\u2019 method with an input to be transformed:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.activate([1, 2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([ 0.6406875])"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, this might look different on your machine - the weights of the connections have already been initialized randomly. To have a look at those parameters, just check the .params field of the connections:\n",
      "\n",
      "We can access the trainable parameters (weights) of a connection directly, or read all weights of the network at once:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([-0.67947299,  0.72575071, -0.33871385, -1.26017814,  0.04008293,\n",
        "       -0.54288999,  0.91642627,  1.16513304, -0.18949237])"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, the last three parameters of the network equal the parameters of the second connection."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Naming your Networks structure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to allow recurrency, networks have to be able to \u201clook back in time\u201d. Due to this, the RecurrentNetwork class is different from the FeedForwardNetwork class in the substantial way, that the complete history is saved. This is actually memory consuming, but necessary for some learning algorithms.\n",
      "\n",
      "To create a recurrent network, just do as with feedforward networks but use the appropriate class:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.structure import RecurrentNetwork\n",
      "n = RecurrentNetwork()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will quickly build up a network that is the same as in the example above:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.addInputModule(LinearLayer(2, name='in'))\n",
      "n.addModule(SigmoidLayer(3, name='hidden'))\n",
      "n.addOutputModule(LinearLayer(1, name='out'))\n",
      "n.addConnection(FullConnection(n['in'], n['hidden'], name='c1'))\n",
      "n.addConnection(FullConnection(n['hidden'], n['out'], name='c2'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The RecurrentNetwork class has one additional method, .addRecurrentConnection(), which looks back in time one timestep. We can add one from the hidden to the hidden layer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.addRecurrentConnection(FullConnection(n['hidden'], n['hidden'], name='c3'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we now activate the network, we will get different outputs each time:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.sortModules()\n",
      "n.activate((2, 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "array([ 0.31800411])"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.activate((2, 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([ 0.38102821])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.activate((2, 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "array([ 0.39156416])"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, we can clear the history of the network. This can be done by calling the reset method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.reset()\n",
      "n.activate((2, 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([ 0.31800411])"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.activate((2, 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "array([ 0.38102821])"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n.activate((2, 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "array([ 0.39156416])"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After the call to .reset(), we are getting the same outputs as just after the objects creation."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification with Feed-Forward Neural Networks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This tutorial walks you through the process of setting up a dataset for classification, and train a network on it while visualizing the results online.\n",
      "\n",
      "First we need to import the necessary components from PyBrain."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.datasets            import ClassificationDataSet\n",
      "from pybrain.utilities           import percentError\n",
      "from pybrain.tools.shortcuts     import buildNetwork\n",
      "from pybrain.supervised.trainers import BackpropTrainer\n",
      "from pybrain.structure.modules   import SoftmaxLayer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Furthermore, pylab is needed for the graphical output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylab import ion, ioff, figure, draw, contourf, clf, show, hold, plot\n",
      "from scipy import diag, arange, meshgrid, where\n",
      "from numpy.random import multivariate_normal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To have a nice dataset for visualization, we produce a set of points in 2D belonging to three different classes. You could also read in your data from a file, e.g. using pylab.load()."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "means = [(-1,0),(2,4),(3,1)]\n",
      "cov = [diag([1,1]), diag([0.5,1.2]), diag([1.5,0.7])]\n",
      "alldata = ClassificationDataSet(2, 1, nb_classes=3)\n",
      "for n in xrange(400):\n",
      "    for klass in range(3):\n",
      "        input = multivariate_normal(means[klass],cov[klass])\n",
      "        alldata.addSample(input, [klass])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Randomly split the dataset into 75% training and 25% test data sets. Of course, we could also have created two different datasets to begin with."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tstdata, trndata = alldata.splitWithProportion( 0.25 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For neural network classification, it is highly advisable to encode classes with one output neuron per class. Note that this operation duplicates the original targets and stores them in an (integer) field named \u2018class\u2019."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trndata._convertToOneOfMany( )\n",
      "tstdata._convertToOneOfMany( )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test our dataset by printing a little information about it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Number of training patterns: \", len(trndata)\n",
      "print \"Input and output dimensions: \", trndata.indim, trndata.outdim\n",
      "print \"First sample (input, target, class):\"\n",
      "print trndata['input'][0], trndata['target'][0], trndata['class'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of training patterns:  900\n",
        "Input and output dimensions:  2 3\n",
        "First sample (input, target, class):\n",
        "[-1.67782479 -1.03364413] [1 0 0] [ 0.]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now build a feed-forward network with 5 hidden units. We use the shortcut buildNetwork() for this. The input and output layer size must match the dataset\u2019s input and target dimension. You could add additional hidden layers by inserting more numbers giving the desired layer sizes.\n",
      "\n",
      "The output layer uses a softmax function because we are doing classification. There are more options to explore here, e.g. try changing the hidden layer transfer function to linear instead of (the default) sigmoid."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fnn = buildNetwork( trndata.indim, 5, trndata.outdim, outclass=SoftmaxLayer )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up a trainer that basically takes the network and training dataset as input. For a list of trainers, see trainers. We are using a BackpropTrainer for this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer = BackpropTrainer( fnn, dataset=trndata, momentum=0.1, verbose=True, weightdecay=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now generate a square grid of data points and put it into a dataset, which we can then classify to obtain a nice contour field for visualization. Therefore the target values for this data set can be ignored."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ticks = arange(-3.,6.,0.2)\n",
      "X, Y = meshgrid(ticks, ticks)\n",
      "# need column vectors in dataset, not arrays\n",
      "griddata = ClassificationDataSet(2,1, nb_classes=3)\n",
      "for i in xrange(X.size):\n",
      "    griddata.addSample([X.ravel()[i],Y.ravel()[i]], [0])\n",
      "griddata._convertToOneOfMany()  # this is still needed to make the fnn feel comfy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start the training iterations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(20):\n",
      "# Train the network for some epochs. \n",
      "# Usually you would set something like 5 here,\n",
      "# but for visualization purposes we do this one epoch at a time.\n",
      "    trainer.trainEpochs( 1 )\n",
      "# Evaluate the network on the training and test data. \n",
      "# There are several ways to do this - check out the pybrain.tools.validation \n",
      "# module, for instance. Here we let the trainer do the test.\n",
      "    trnresult = percentError( trainer.testOnClassData(),\n",
      "                              trndata['class'] )\n",
      "    tstresult = percentError( trainer.testOnClassData(\n",
      "           dataset=tstdata ), tstdata['class'] )\n",
      "\n",
      "    print \"epoch: %4d\" % trainer.totalepochs, \\\n",
      "          \"  train error: %5.2f%%\" % trnresult, \\\n",
      "          \"  test error: %5.2f%%\" % tstresult\n",
      "            \n",
      "# Run our grid data through the FNN, get the most likely class \n",
      "# and shape it into a square array again.\n",
      "    out = fnn.activateOnDataset(griddata)\n",
      "    out = out.argmax(axis=1)  # the highest output activation gives the class\n",
      "    out = out.reshape(X.shape)\n",
      "    \n",
      "# Now plot the test data and the underlying grid as a filled contour.\n",
      "    figure(1)\n",
      "    ioff()  # interactive graphics off\n",
      "    clf()   # clear the plot\n",
      "    hold(True) # overplot on\n",
      "    for c in [0,1,2]:\n",
      "        here, _ = where(tstdata['class']==c)\n",
      "        plot(tstdata['input'][here,0],tstdata['input'][here,1],'o')\n",
      "    if out.max()!=out.min():  # safety check against flat field\n",
      "        contourf(X, Y, out)   # plot the contour\n",
      "    ion()   # interactive graphics on\n",
      "    draw()  # update the plot\n",
      "\n",
      "# Finally, keep showing the plot until user kills it. \n",
      "ioff()\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total error: 0.0187862534989\n",
        "epoch:   41"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.22%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187841710638\n",
        "epoch:   42"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.00%   test error:  4.67%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0188366073673\n",
        "epoch:   43"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.00%   test error:  5.33%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0188562387656\n",
        "epoch:   44"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.22%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187872297284\n",
        "epoch:   45"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  5.89%   test error:  5.67%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187440951334\n",
        "epoch:   46"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.00%   test error:  4.67%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.018787574401\n",
        "epoch:   47"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.44%   test error:  5.33%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0188553049414\n",
        "epoch:   48"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.00%   test error:  4.67%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0188427834756\n",
        "epoch:   49"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.22%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187611779985\n",
        "epoch:   50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.11%   test error:  5.33%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187781416082\n",
        "epoch:   51"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  5.89%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187279217386\n",
        "epoch:   52"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.11%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0186466835296\n",
        "epoch:   53"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.00%   test error:  4.67%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0186710116652\n",
        "epoch:   54"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.00%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187403149067\n",
        "epoch:   55"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.11%   test error:  4.67%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187318602393\n",
        "epoch:   56"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.11%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0186005476893\n",
        "epoch:   57"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.11%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187444109063\n",
        "epoch:   58"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.11%   test error:  4.67%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187743221462\n",
        "epoch:   59"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.00%   test error:  5.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0187250118391\n",
        "epoch:   60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  5.89%   test error:  5.00%\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using Datasets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Datasets are useful for allowing comfortable access to training, test and validation data. Instead of having to mangle with arrays, PyBrain gives you a more sophisticated datastructure that allows easier work with your data.\n",
      "\n",
      "For the different tasks that arise in machine learning, there is a special dataset type, possibly with a few sub-types. The different types share some common functionality, which we\u2019ll discuss first.\n",
      "\n",
      "A dataset can be seen as a collection of named 2d-arrays, called fields in this context. For instance, if DS implements DataSet:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inp = DS['input']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'DS' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-60-1ba3afc6dc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'DS' is not defined"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "returns the input field. The last dimension of this field corresponds to the input dimension, such that"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inp[0,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'inp' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-61-9a12eb8a8983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'inp' is not defined"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "would yield the first input vector. In most cases there is also a field named \u2018target\u2019, which follows the same rules. However, didn\u2019t we say we will spare you the array mangling? Well, in most cases you will want iterate over a dataset like so:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for inp, targ in DS:\n",
      "  ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-62-75b8e8886e7f>, line 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-62-75b8e8886e7f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ...\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that whether you get one, two, or more sample rows as a return depends on the number of linked fields in the DataSet: These are fields containing the same number of samples and assumed to be used together, like the above \u2018input\u2019 and \u2018target\u2019 fields. You can always check the DS.link property to see which fields are linked.\n",
      "\n",
      "Similarly, DataSets can be created by adding samples one-by-one \u2013 the cleaner but slower method \u2013 or by assembling them from arrays."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for inp, targ in samples:\n",
      "    DS.appendLinked(inp, targ)\n",
      "# or alternatively, with  ia  and  ta  being arrays:\n",
      "assert(ia.shape[0] == ta.shape[0])\n",
      "DS.setField('input', ia)\n",
      "DS.setField('target', ta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'samples' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-64-564327161950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappendLinked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# or alternatively, with  ia  and  ta  being arrays:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mia\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the latter case DS cannot check the linked array dimensions for you, otherwise it would not be possible to build a dataset from scratch.\n",
      "\n",
      "You may add your own linked or unlinked data to the dataset. However, note that many training algorithms iterate over the linked fields and may fail if their number has changed:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DS.addField('myfield')\n",
      "DS.setField('myfield', myarray)\n",
      "DS.linkFields('input','target','myfield') # must provide complete list here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'DS' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-65-e5ae6afe2a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'myfield'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'myfield'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinkFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'myfield'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# must provide complete list here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'DS' is not defined"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A useful utility method for quick generation of randomly picked training and testing data is also provided:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> len(DS)\n",
      "100\n",
      ">>> TrainDS, TestDS = DS.splitWithProportion(0.8)\n",
      ">>> len(TrainDS), len(TestDS)\n",
      "(80, 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'DS' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-66-8b9ef3726481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTrainDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitWithProportion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'DS' is not defined"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "supervised \u2013 Dataset for Supervised Regression Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As the name says, this simplest form of a dataset is meant to be used with supervised learning tasks. It is comprised of the fields \u2018input\u2019 and \u2018target\u2019, the pattern size of which must be set upon creation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.datasets import SupervisedDataSet\n",
      "DS = SupervisedDataSet( 3, 2 )\n",
      "DS.appendLinked( [1,2,3], [4,5] )\n",
      "len(DS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DS['input']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "array([[ 1.,  2.,  3.]])"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "sequential \u2013 Dataset for Supervised Sequences Regression Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This dataset introduces the concept of sequences. With this we are moving further away from the array mangling towards something more practical for sequence learning tasks. Essentially, its patterns are subdivided into sequences of variable length, that can be accessed via the methods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getNumSequences()\n",
      "getSequence(index)\n",
      "getSequenceLength(index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'getNumSequences' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-71-ab42828710cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetNumSequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgetSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgetSequenceLength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'getNumSequences' is not defined"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Creating a Sequentialdataset is no different from its parent, since it still contains only \u2018input\u2019 and \u2018target\u2019 fields. Sequentialdataset inherits from SupervisedDataSet, which can be seen as a special case with a sequence length of 1 for all sequences.\n",
      "\n",
      "To fill the dataset with content, it is advisable to call newSequence() at the start of each sequence to be stored, and then add patterns by using appendLinked() as above. This way, the class handles indexing and such transparently. One can theoretically construct a Sequentialdataset directly from arrays, but messing with the index field is not recommended.\n",
      "\n",
      "A typical way of iterating over a sequence dataset DS would be something like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(DS.getNumSequences):\n",
      "    for input, target in DS.getSequenceIterator(i):\n",
      "       # do stuff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-72-60f762435288>, line 3)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-72-60f762435288>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    # do stuff\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "classification \u2013 Datasets for Supervised Classification Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The purpose of this dataset is to facilitate dealing with classification problems, whereas the above are more geared towards regression. Its \u2018target\u2019 field is defined as integer, and it contains an extra field called \u2018class\u2019 which is basically an automated backup of the targets, for reasons that we be apparent shortly. For the most part, you don\u2019t have to bother with it. Initialization requires something like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DS = ClassificationDataSet(inputdim, nb_classes=2, class_labels=['Fish','Chips'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'inputdim' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-74-1c5dc0284764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fish'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Chips'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'inputdim' is not defined"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The labels are optional, and mainly used for documentation. Target dimension is supposed to be 1. The targets are class labels starting from zero. If for some reason you don\u2019t know beforehand how many you have, or you fiddled around with the setField() method, it is possible to regenerate the class information using assignClasses(), or calculateStatistics():"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DS = ClassificationDataSet(2, class_labels=['Urd', 'Verdandi', 'Skuld'])\n",
      "DS.appendLinked([ 0.1, 0.5 ]   , [0])\n",
      "DS.appendLinked([ 1.2, 1.2 ]   , [1])\n",
      "DS.appendLinked([ 1.4, 1.6 ]   , [1])\n",
      "DS.appendLinked([ 1.6, 1.8 ]   , [1])\n",
      "DS.appendLinked([ 0.10, 0.80 ] , [2])\n",
      "DS.appendLinked([ 0.20, 0.90 ] , [2])\n",
      "\n",
      "DS.calculateStatistics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "{0: 1, 1: 3, 2: 2}"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print DS.classHist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{0: 1, 1: 3, 2: 2}\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print DS.getClass(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Verdandi\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print DS.getField('target').transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 1 1 2 2]]\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When doing classification, many algorithms work better if classes are encoded into one output unit per class, that takes on a certain value if the class is present. As an advanced feature, ClassificationDataSet does this conversion automatically:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DS._convertToOneOfMany(bounds=[0, 1])\n",
      "print DS.getField('target')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1 0 0]\n",
        " [0 1 0]\n",
        " [0 1 0]\n",
        " [0 1 0]\n",
        " [0 0 1]\n",
        " [0 0 1]]\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print DS.getField('class').transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 1 1 2 2]]\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DS._convertToClassNb()\n",
      "print DS.getField('target').transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 1 1 2 2]]\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In case you want to do sequence classification, there is also a SequenceClassificationDataSet, which combines the features of this class and the Sequentialdataset."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "importance \u2013 Datasets for Weighted Supervised Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is another extension of Sequentialdataset that allows assigning different weights to patterns. Essentially, it works like its parent, except comprising another linked field named \u2018importance\u2019, which should contain a value between 0.0 and 1.0 for each pattern. A Sequentialdataset is a special case with all weights equal to 1.0.\n",
      "\n",
      "We have packed this functionality into a different class because it is rarely used and drains some computational resources. So far, there is no corresponding non-sequential dataset class."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Black-box Optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This tutorial will illustrate how to use the optimization algorithms in PyBrain.\n",
      "\n",
      "Very many practical problems can be framed as optimization problems: finding the best settings for a controller, minimizing the risk of an investment portfolio, finding a good strategy in a game, etc. It always involves determining a certain number of variables (the problem dimension), each of them chosen from a set, that maximizing (or minimize) a given objective function.\n",
      "\n",
      "The main categories of optimization problems are based on the kinds of sets the variables are chosen from:\n",
      "\n",
      "        all real numbers: continuous optimization\n",
      "        real numbers with bounds: constrained optimization\n",
      "        integers: integer programming\n",
      "        combinations of the above\n",
      "        others, e.g. graphs\n",
      "\n",
      "These can be further classified according to properties of the objective function (e.g. continuity, explicit access to partial derivatives, quadratic form, etc.). In black-box optimization the objective function is a black box, i.e. there are no conditions about it. The optimization tools that PyBrain provides are all for the most general, black-box case. They fall into 2 groups:\n",
      "\n",
      "        BlackBoxOptimizer are applicable to all kinds of variable sets\n",
      "        ContinuousOptimizer can only be used for continuous optimization\n",
      "\n",
      "We will introduce the optimization framework for the more restrictive kind first, because that case is simpler."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Continuous optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let\u2019s start by defining a simple objective function for (numpy arrays of) continuous variables, e.g. the sum of squares:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " def objF(x): return sum(x**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and an initial guess for where to start looking:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import array\n",
      "x0 = array([2.1, -1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can initialize one of the optimization algorithms, e.g. CMAES:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.optimization import CMAES\n",
      "l = CMAES(objF, x0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default, all optimization algorithms maximize the objective function, but you can change this by setting the minimize attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l.minimize = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Note\n",
      "\n",
      "We could also have done that upon construction: CMAES(objF, x0, minimize = True) "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Stopping criteria can be algorithm-specific, but in addition, it is always possible to define the following ones:\n",
      "\n",
      "* maximal number of evaluations\n",
      "* maximal number of learning steps\n",
      "* reaching a desired value\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l.maxEvaluations = 200"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the optimizer is set up, all we need to use is the learn() method, which will attempt to optimize the variables until a stopping criterion is reached. It returns a tuple with the best evaluable (= array of variables) found, and the corresponding fitness:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l.learn()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "(array([ -3.89489486e-04,   2.01148545e-05]), 1.5210666726768188e-07)"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "General optimization: using Evolvable"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our approach to doing optimization in the most general setting (no assumptions about the variables) is to let the user define a subclass of Evolvable that implements:\n",
      "\n",
      "* a copy() operator,\n",
      "* a method for generating random other points: randomize(),\n",
      "* mutate(), an operator that does a small step in search space, according to some distance metric,\n",
      "* (optionally) a crossover() operator that produces some combination with other evolvables of the same class.\n",
      "\n",
      "The optimization algorithm is then initialized with an instance of this class and an objective function that can evaluate such instances.\n",
      "\n",
      "Here\u2019s a minimalistic example of such a subclass with a single constrained variable (and a bias to do mutation steps toward larger values):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from random import random\n",
      "from pybrain.structure.evolvables.evolvable import Evolvable\n",
      "class SimpleEvo(Evolvable):\n",
      "    def __init__(self, x): self.x = max(0, min(x, 10))\n",
      "    def mutate(self):      self.x = max(0, min(self.x + random() - 0.3, 10))\n",
      "    def copy(self):        return SimpleEvo(self.x)\n",
      "    def randomize(self):   self.x = 10*random()\n",
      "    def __repr__(self):    return '<-%.2f->'+str(self.x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "which can be optimized using, for example, HillClimber:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.optimization import HillClimber\n",
      "x0 = SimpleEvo(1.2)\n",
      "l = HillClimber(lambda x: x.x, x0, maxEvaluations = 50)\n",
      "l.learn()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 93,
       "text": [
        "(<-%.2f->10, 10)"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Optimization in Reinforcement Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section illustrates how to use optimization algorithms in the reinforcement learning framework.\n",
      "\n",
      "As our objective function we use any episodic task, e.g:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.rl.environments.cartpole.balancetask import BalanceTask\n",
      "task = BalanceTask()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then we construct a module that can interact with the task, for example a neural network controller,"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.tools.shortcuts import buildNetwork\n",
      "net = buildNetwork(task.outdim, 3, task.indim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and we choose any optimization algorithm, e.g. a simple HillClimber.\n",
      "\n",
      "Now, we have 2 (equivalent) ways for connecting those:\n",
      "\n",
      "1) using the same syntax as before, where the task plays the role of the objective function directly:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HillClimber(task, net, maxEvaluations = 100).learn()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "(<FeedForwardNetwork 'FeedForwardNetwork-105'>, -1991.0)"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2) or, using the agent-based framework:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.rl.agents import OptimizationAgent\n",
      "from pybrain.rl.experiments import EpisodicExperiment\n",
      "agent = OptimizationAgent(net, HillClimber())\n",
      "exp = EpisodicExperiment(task, agent)\n",
      "exp.doEpisodes(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note\n",
      "\n",
      "This is very similar to the typical (non-optimization) reinforcement learning setup, the key difference being the use of a LearningAgent instead of an OptimizationAgent."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.rl.learners import ENAC\n",
      "from pybrain.rl.agents import LearningAgent\n",
      "agent = LearningAgent(net, ENAC())\n",
      "exp = EpisodicExperiment(task, agent)\n",
      "exp.doEpisodes(100)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "[[-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, 0, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [0, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1990],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [0, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, 0, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [0, 0, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1990],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, 0, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [0, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, 0, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [0, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1990],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, 0, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1988],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986],\n",
        " [-1, -1, -1, -1, -1, -1, -1986]]"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Reinforcement Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A reinforcement learning (RL) task in PyBrain always consists of a few components that interact with each other: Environment, Agent, Task, and Experiment. In this tutorial we will go through each of them, create the instances and explain what they do."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![alt text](http://pybrain.org/docs/_images/rl.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But first of all, we need to import some general packages and the RL components from PyBrain:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import *\n",
      "import sys, time\n",
      "\n",
      "from pybrain.rl.environments.mazes import Maze, MDPMazeTask\n",
      "from pybrain.rl.learners.valuebased import ActionValueTable\n",
      "from pybrain.rl.agents import LearningAgent\n",
      "from pybrain.rl.learners import Q, SARSA\n",
      "from pybrain.rl.experiments import Experiment\n",
      "from pybrain.rl.environments import Task"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Note\n",
      "\n",
      "You can directly run the code in this tutorial by running the script docs/tutorials/rl.py. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For later visualization purposes, we also need to initialize the plotting engine (interactive mode)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pylab\n",
      "pylab.gray()\n",
      "pylab.ion()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Environment is the world, in which the agent acts. It receives input with the performAction() method and returns an output with getSensors(). All environments in PyBrain are located under pybrain/rl/environments."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of these environments is the maze environment, which we will use for this tutorial. It creates a labyrinth with free fields, walls, and an goal point. An agent can move over the free fields and needs to find the goal point. Let\u2019s define the maze structure, a simple 2D numpy array, where 1 is a wall and 0 is a free field:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "structure = array([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                   [1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
      "                   [1, 0, 0, 1, 0, 0, 1, 0, 1],\n",
      "                   [1, 0, 0, 1, 0, 0, 1, 0, 1],\n",
      "                   [1, 0, 0, 1, 0, 1, 1, 0, 1],\n",
      "                   [1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
      "                   [1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
      "                   [1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "                   [1, 1, 1, 1, 1, 1, 1, 1, 1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then we create the environment with the structure as first parameter and the goal field tuple as second parameter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "environment = Maze(structure, (7, 7))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we need an agent. The agent is where the learning happens. It can interact with the environment with its getAction() and integrateObservation() methods.\n",
      "\n",
      "The agent itself consists of a controller, which maps states to actions, a learner, which updates the controller parameters according to the interaction it had with the world, and an explorer, which adds some explorative behavior to the actions. All standard agents already have a default explorer, so we don\u2019t need to take care of that in this tutorial.\n",
      "\n",
      "The controller in PyBrain is a module, that takes states as inputs and transforms them into actions. For value-based methods, like the Q-Learning algorithm we will use here, we need a module that implements the ActionValueInterface. There are currently two modules in PyBrain that do this: The ActionValueTable for discrete actions and the ActionValueNetwork for continuous actions. Our maze uses discrete actions, so we need a table:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "controller = ActionValueTable(81, 4)\n",
      "controller.initialize(1.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The table needs the number of states and actions as parameters. The standard maze environment comes with the following 4 actions: north, south, east, west.\n",
      "\n",
      "Then, we initialize the table with 1 everywhere. This is not always necessary but will help converge faster, because unvisited state-action pairs have a promising positive value and will be preferred over visited ones that didn\u2019t lead to the goal.\n",
      "\n",
      "Each agent also has a learner component. Several classes of RL learners are currently implemented in PyBrain: black box optimizers, direct search methods, and value-based learners. The classical Reinforcement Learning mostly consists of value-based learning, in which of the most well-known algorithms is the Q-Learning algorithm. Let\u2019s now create the agent and give it the controller and learner as parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "learner = Q()\n",
      "agent = LearningAgent(controller, learner)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So far, there is no connection between the agent and the environment. In fact, in PyBrain, there is a special component that connects environment and agent: the task. A task also specifies what the goal is in an environment and how the agent is rewarded for its actions. For episodic experiments, the Task also decides when an episode is over. Environments usually bring along their own tasks. The Maze environment for example has a MDPMazeTask, that we will use. MDP stands for \u201cmarkov decision process\u201d and means here, that the agent knows its exact location in the maze. The task receives the environment as parameter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "task = MDPMazeTask(environment)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, in order to learn something, we create an experiment, tell it both task and agent (it knows the environment through the task) and let it run for some number of steps or infinitely, like here:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "experiment = Experiment(task, agent)\n",
      "\n",
      "while True:\n",
      "    experiment.doInteractions(100)\n",
      "    agent.learn()\n",
      "    agent.reset()\n",
      "\n",
      "    pylab.pcolor(controller.params.reshape(81,4).max(1).reshape(9,9))\n",
      "    pylab.draw()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}